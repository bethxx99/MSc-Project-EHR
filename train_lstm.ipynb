{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_lstm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9ba8dc6efbc44ec8bdda800e59b1b370":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ad2a3f8b04c4ef7b7066513b4bb33b0","IPY_MODEL_1e65f2d9cf484c10a76a4a198b8731b2"],"layout":"IPY_MODEL_3936dde1b8284244a4892222c5bdb1a0"}},"5ad2a3f8b04c4ef7b7066513b4bb33b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_7a7663a3fba443599c6c2a80855c17ff","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_227f7e4226ad427693b909ce75435356","value":313}},"1e65f2d9cf484c10a76a4a198b8731b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af06d867a3ec4c48857dd094c9d02fc7","placeholder":"​","style":"IPY_MODEL_c15092fa6c62481f8be0f766c5cc02f2","value":" 313/313 [00:13&lt;00:00, 23.0B/s]"}},"3936dde1b8284244a4892222c5bdb1a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a7663a3fba443599c6c2a80855c17ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227f7e4226ad427693b909ce75435356":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"af06d867a3ec4c48857dd094c9d02fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c15092fa6c62481f8be0f766c5cc02f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7acdda52ebbc4efca0a34d4bc2715fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e223b9130994494ea39ee09b6f9227c8","IPY_MODEL_582a2f66d76b45f388a05f696fce62f9"],"layout":"IPY_MODEL_81671587e6f74c0b937306cabb8925b7"}},"e223b9130994494ea39ee09b6f9227c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_4da6255b6ca046d5944219efffbca65e","max":440512265,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90ac2355a6ad418d925813c7fa24b5e5","value":440512265}},"582a2f66d76b45f388a05f696fce62f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff435c43c8a408cab6d886518c8f242","placeholder":"​","style":"IPY_MODEL_a09beabf3a6a49bba53ff1c937d3e3c4","value":" 441M/441M [00:12&lt;00:00, 34.6MB/s]"}},"81671587e6f74c0b937306cabb8925b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da6255b6ca046d5944219efffbca65e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ac2355a6ad418d925813c7fa24b5e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"4ff435c43c8a408cab6d886518c8f242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a09beabf3a6a49bba53ff1c937d3e3c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc846f3cee5247dba6a08fec6565cd0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f659d11c9cd545acbc6355db2a0eb5d7","IPY_MODEL_23ea353eb39c49129b59b603ef881dd4"],"layout":"IPY_MODEL_d437ddd4f50b4eaaa72cef22e81f53e6"}},"f659d11c9cd545acbc6355db2a0eb5d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_de829baf8efa40609e49b2c1ffec0f6a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e857efb93364ac2930f63b10e9e2073","value":231508}},"23ea353eb39c49129b59b603ef881dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b8a7902419040d584eab7db37e05d72","placeholder":"​","style":"IPY_MODEL_bb3fc9732e314fcfb17834a9f26f988d","value":" 232k/232k [00:01&lt;00:00, 118kB/s]"}},"d437ddd4f50b4eaaa72cef22e81f53e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de829baf8efa40609e49b2c1ffec0f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e857efb93364ac2930f63b10e9e2073":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"6b8a7902419040d584eab7db37e05d72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3fc9732e314fcfb17834a9f26f988d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXUVchdOtJH3","executionInfo":{"elapsed":8163,"status":"ok","timestamp":1628596120922,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"cf920c8b-e6d1-43a6-f6a0-74d8c58e350f"},"source":["!pip install -q transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.6 MB 14.7 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 53.5 MB/s \n","\u001b[K     |████████████████████████████████| 636 kB 52.0 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 57.0 MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRKb2upttLqT","executionInfo":{"elapsed":19668,"status":"ok","timestamp":1628596140572,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"8118a954-3e11-482d-fb64-cdf9eb9852eb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NyBB72MsrfK8"},"source":["%matplotlib inline\n","import torch\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import re\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import transformers\n","from transformers import RobertaTokenizer, BertTokenizer, RobertaModel, BertModel, AdamW# get_linear_schedule_with_warmup\n","from transformers import get_linear_schedule_with_warmup\n","import time\n","\n","!cp drive/MyDrive/Colab\\ Notebooks/MSc-Individual-Project/utils_lstm.py .\n","from utils_lstm import *\n","!cp drive/MyDrive/Colab\\ Notebooks/MSc-Individual-Project/Custom_Dataset_Class.py .\n","from Custom_Dataset_Class import CustomDataset\n","#from Bert_Classification import Bert_Classification_Model\n","#from RoBERT import RoBERT_Model\n","\n","#from BERT_Hierarchical import BERT_Hierarchical_Model\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.preprocessing import LabelBinarizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ao6DEnzMrfLA","executionInfo":{"elapsed":23,"status":"ok","timestamp":1628596146208,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"430fc361-c1db-4898-e4a8-9f0f4a20aee2"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"clgth891rfLB","executionInfo":{"elapsed":12974,"status":"ok","timestamp":1628596159171,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"4e20743a-88b4-4689-f5a1-e1bc78abed74"},"source":["#change to where you store mimic3 data\n","MIMIC_3_DIR = '/content/drive/MyDrive/Colab Notebooks/MSc-Individual-Project/datasets'\n","\n","train_df = pd.read_csv('%s/train_50.csv' % MIMIC_3_DIR)\n","eval_df = pd.read_csv('%s/dev_50.csv' % MIMIC_3_DIR)\n","test_df = pd.read_csv('%s/test_50.csv' % MIMIC_3_DIR)\n","\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID</th>\n","      <th>TEXT</th>\n","      <th>LABELS</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4108</td>\n","      <td>117347</td>\n","      <td>admit pt was admitted from a location un at pt...</td>\n","      <td>272.0</td>\n","      <td>304</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24464</td>\n","      <td>145442</td>\n","      <td>admission date discharge date date of birth se...</td>\n","      <td>401.9</td>\n","      <td>337</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13329</td>\n","      <td>103551</td>\n","      <td>unit no numeric identifier admission date disc...</td>\n","      <td>530.81;403.91;414.01;305.1;272.0</td>\n","      <td>345</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22005</td>\n","      <td>126862</td>\n","      <td>unit no numeric identifier admission date disc...</td>\n","      <td>285.1</td>\n","      <td>347</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26993</td>\n","      <td>194796</td>\n","      <td>admission date discharge date date of birth se...</td>\n","      <td>272.4;250.00;V45.81;414.01;401.9</td>\n","      <td>367</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SUBJECT_ID  HADM_ID  ...                            LABELS length\n","0        4108   117347  ...                             272.0    304\n","1       24464   145442  ...                             401.9    337\n","2       13329   103551  ...  530.81;403.91;414.01;305.1;272.0    345\n","3       22005   126862  ...                             285.1    347\n","4       26993   194796  ...  272.4;250.00;V45.81;414.01;401.9    367\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"HkDdZEcA3oIY"},"source":["full_df = pd.concat([train_df, eval_df, test_df], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"4czBKoJhrfLC","executionInfo":{"elapsed":1167,"status":"ok","timestamp":1628596160312,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"266fe200-595e-45b7-ab26-00d23fe2730e"},"source":["# split labels by \";\", then convert to list\n","def split_lab (x):\n","    #print(x)\n","    return x.split(\";\")\n","\n","full_df['LABELS'] = full_df['LABELS'].apply(split_lab)\n","full_df['TEXT'] = full_df['TEXT'].apply(split_lab)\n","\n","full_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID</th>\n","      <th>TEXT</th>\n","      <th>LABELS</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4108</td>\n","      <td>117347</td>\n","      <td>[admit pt was admitted from a location un at p...</td>\n","      <td>[272.0]</td>\n","      <td>304</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24464</td>\n","      <td>145442</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>[401.9]</td>\n","      <td>337</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13329</td>\n","      <td>103551</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>[530.81, 403.91, 414.01, 305.1, 272.0]</td>\n","      <td>345</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22005</td>\n","      <td>126862</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>[285.1]</td>\n","      <td>347</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26993</td>\n","      <td>194796</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>[272.4, 250.00, V45.81, 414.01, 401.9]</td>\n","      <td>367</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SUBJECT_ID  HADM_ID  ...                                  LABELS length\n","0        4108   117347  ...                                 [272.0]    304\n","1       24464   145442  ...                                 [401.9]    337\n","2       13329   103551  ...  [530.81, 403.91, 414.01, 305.1, 272.0]    345\n","3       22005   126862  ...                                 [285.1]    347\n","4       26993   194796  ...  [272.4, 250.00, V45.81, 414.01, 401.9]    367\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"4j8T0k-UrfLE"},"source":["#load multi label binarizer for one-hot encoding\n","mlb = MultiLabelBinarizer(sparse_output=True)\n","\n","#labels_onehot = mlb.fit_transform(train_df.pop('LABELS'))\n","#labels_onehot[0][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581},"id":"EWSkkSjGrfLF","executionInfo":{"elapsed":55,"status":"ok","timestamp":1628596160343,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"13a4b86b-d24b-483f-95ca-21313eaf23e9"},"source":["#change label to one-hot encoding per code\n","full_df = full_df.join(\n","            pd.DataFrame.sparse.from_spmatrix(\n","                mlb.fit_transform(full_df.pop('LABELS')),\n","                columns=mlb.classes_))\n","\n","full_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID</th>\n","      <th>TEXT</th>\n","      <th>length</th>\n","      <th>038.9</th>\n","      <th>244.9</th>\n","      <th>250.00</th>\n","      <th>272.0</th>\n","      <th>272.4</th>\n","      <th>276.0</th>\n","      <th>276.1</th>\n","      <th>276.2</th>\n","      <th>285.1</th>\n","      <th>285.9</th>\n","      <th>287.5</th>\n","      <th>305.1</th>\n","      <th>311</th>\n","      <th>327.23</th>\n","      <th>401.9</th>\n","      <th>403.90</th>\n","      <th>403.91</th>\n","      <th>410.71</th>\n","      <th>412</th>\n","      <th>414.01</th>\n","      <th>424.0</th>\n","      <th>424.1</th>\n","      <th>427.31</th>\n","      <th>427.89</th>\n","      <th>428.0</th>\n","      <th>486</th>\n","      <th>493.90</th>\n","      <th>496</th>\n","      <th>507.0</th>\n","      <th>511.9</th>\n","      <th>518.0</th>\n","      <th>518.81</th>\n","      <th>530.81</th>\n","      <th>584.5</th>\n","      <th>584.9</th>\n","      <th>585.9</th>\n","      <th>599.0</th>\n","      <th>774.2</th>\n","      <th>785.52</th>\n","      <th>995.92</th>\n","      <th>997.1</th>\n","      <th>V05.3</th>\n","      <th>V15.82</th>\n","      <th>V29.0</th>\n","      <th>V30.00</th>\n","      <th>V30.01</th>\n","      <th>V45.81</th>\n","      <th>V45.82</th>\n","      <th>V58.61</th>\n","      <th>V58.67</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4108</td>\n","      <td>117347</td>\n","      <td>[admit pt was admitted from a location un at p...</td>\n","      <td>304</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24464</td>\n","      <td>145442</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>337</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13329</td>\n","      <td>103551</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>345</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22005</td>\n","      <td>126862</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>347</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26993</td>\n","      <td>194796</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>367</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SUBJECT_ID  HADM_ID  ... V58.61  V58.67\n","0        4108   117347  ...      0       0\n","1       24464   145442  ...      0       0\n","2       13329   103551  ...      0       0\n","3       22005   126862  ...      0       0\n","4       26993   194796  ...      0       0\n","\n","[5 rows x 54 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"id":"x3XgCsYhrfLG","executionInfo":{"elapsed":46,"status":"ok","timestamp":1628596160344,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"6b595a8d-ac4d-4da6-fb55-f3f4e125b964"},"source":["# Convert columns to list of one hot encoding\n","icd_classes_50 = mlb.classes_\n","\n","full_df['labels'] = full_df[icd_classes_50].values.tolist()\n","#train_df.sort_values(['length'], ascending=False, inplace=True)\n","full_df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID</th>\n","      <th>TEXT</th>\n","      <th>length</th>\n","      <th>038.9</th>\n","      <th>244.9</th>\n","      <th>250.00</th>\n","      <th>272.0</th>\n","      <th>272.4</th>\n","      <th>276.0</th>\n","      <th>276.1</th>\n","      <th>276.2</th>\n","      <th>285.1</th>\n","      <th>285.9</th>\n","      <th>287.5</th>\n","      <th>305.1</th>\n","      <th>311</th>\n","      <th>327.23</th>\n","      <th>401.9</th>\n","      <th>403.90</th>\n","      <th>403.91</th>\n","      <th>410.71</th>\n","      <th>412</th>\n","      <th>414.01</th>\n","      <th>424.0</th>\n","      <th>424.1</th>\n","      <th>427.31</th>\n","      <th>427.89</th>\n","      <th>428.0</th>\n","      <th>486</th>\n","      <th>493.90</th>\n","      <th>496</th>\n","      <th>507.0</th>\n","      <th>511.9</th>\n","      <th>518.0</th>\n","      <th>518.81</th>\n","      <th>530.81</th>\n","      <th>584.5</th>\n","      <th>584.9</th>\n","      <th>585.9</th>\n","      <th>599.0</th>\n","      <th>774.2</th>\n","      <th>785.52</th>\n","      <th>995.92</th>\n","      <th>997.1</th>\n","      <th>V05.3</th>\n","      <th>V15.82</th>\n","      <th>V29.0</th>\n","      <th>V30.00</th>\n","      <th>V30.01</th>\n","      <th>V45.81</th>\n","      <th>V45.82</th>\n","      <th>V58.61</th>\n","      <th>V58.67</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4108</td>\n","      <td>117347</td>\n","      <td>[admit pt was admitted from a location un at p...</td>\n","      <td>304</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24464</td>\n","      <td>145442</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>337</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13329</td>\n","      <td>103551</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>345</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22005</td>\n","      <td>126862</td>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>347</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26993</td>\n","      <td>194796</td>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>367</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SUBJECT_ID  ...                                             labels\n","0        4108  ...  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1       24464  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n","2       13329  ...  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n","3       22005  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n","4       26993  ...  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n","\n","[5 rows x 55 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"7KGuG_E4307S"},"source":["train_df, test_df = train_test_split(full_df, test_size=0.15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mR8ud5Ux5E9p"},"source":["train_df.sort_values(['length'], inplace=True)\n","test_df.sort_values(['length'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"M4svTxdlrfLH","executionInfo":{"elapsed":24,"status":"ok","timestamp":1628596160695,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"c6454823-bec1-4535-c476-d34585d66fe7"},"source":["#convert into 2 columns dataframe\n","train_df = pd.DataFrame(train_df, columns=['TEXT', 'labels'])\n","train_df.columns=['text', 'labels']\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[admit pt was admitted from a location un at p...</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[unit no numeric identifier admission date dis...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[admission date discharge date date of birth s...</td>\n","      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text                                             labels\n","0  [admit pt was admitted from a location un at p...  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1  [admission date discharge date date of birth s...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n","2  [unit no numeric identifier admission date dis...  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n","3  [unit no numeric identifier admission date dis...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n","4  [admission date discharge date date of birth s...  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ..."]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9ba8dc6efbc44ec8bdda800e59b1b370","5ad2a3f8b04c4ef7b7066513b4bb33b0","1e65f2d9cf484c10a76a4a198b8731b2","3936dde1b8284244a4892222c5bdb1a0","7a7663a3fba443599c6c2a80855c17ff","227f7e4226ad427693b909ce75435356","af06d867a3ec4c48857dd094c9d02fc7","c15092fa6c62481f8be0f766c5cc02f2","7acdda52ebbc4efca0a34d4bc2715fc8","e223b9130994494ea39ee09b6f9227c8","582a2f66d76b45f388a05f696fce62f9","81671587e6f74c0b937306cabb8925b7","4da6255b6ca046d5944219efffbca65e","90ac2355a6ad418d925813c7fa24b5e5","4ff435c43c8a408cab6d886518c8f242","a09beabf3a6a49bba53ff1c937d3e3c4"]},"id":"aebIQEJwrfLI","executionInfo":{"elapsed":20728,"status":"ok","timestamp":1628596181403,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"0ac2e7ed-f95d-454c-c2c0-173134ef6f9a"},"source":["# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n","\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        '''\n","            Load Pretrained model here\n","            Use return_dict=False for compatibility for 4.x\n","\n","        '''\n","        self.l1 = transformers.AutoModel.from_pretrained(\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\", return_dict=False)\n","        #self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n","\n","\n","        self.l2 = torch.nn.Dropout(0.3)\n","\n","        self.l3 = nn.LSTM(768, 200, num_layers=1, bidirectional=False)\n","\n","        '''\n","            Changed Linear Output layer to 50 based on the class\n","        '''\n","        self.l4 = torch.nn.Linear(200, 50)\n","\n","\n","\n","    def forward(self, ids, mask, token_type_ids, cell_states):\n","#        print(\"ids: \", ids.size(), \"mask: \", mask.size(), \"token type ids: \", token_type_ids.size())\n","        hx, cx = cell_states\n","        hx = hx.detach()\n","#        print(hx)\n","        cx = cx.detach()\n","\n","        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        output_2 = self.l2(output_1) # # of notes * 768\n","#        print(\"output_2:\", output_2.size())\n","        lstm_input = output_2.unsqueeze(0) # [batch size(1), sequence length(# of notes), input size(786)]\n","        lstm_input = lstm_input.transpose(0, 1)\n","        output_3, cell_states = self.l3(lstm_input, (hx, cx)) # lstm\n","        output = self.l4(output_3)\n","#        print(\"out:\", output.size())\n","#        print(\"out_sq:\", output.squeeze().size())\n","        return output.squeeze(1), cell_states\n","\n","model = BERTClass()\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ba8dc6efbc44ec8bdda800e59b1b370","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=313.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7acdda52ebbc4efca0a34d4bc2715fc8","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440512265.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): LSTM(768, 200)\n","  (l4): Linear(in_features=200, out_features=50, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["cc846f3cee5247dba6a08fec6565cd0c","f659d11c9cd545acbc6355db2a0eb5d7","23ea353eb39c49129b59b603ef881dd4","d437ddd4f50b4eaaa72cef22e81f53e6","de829baf8efa40609e49b2c1ffec0f6a","7e857efb93364ac2930f63b10e9e2073","6b8a7902419040d584eab7db37e05d72","bb3fc9732e314fcfb17834a9f26f988d"]},"id":"ZNP3jntUrfLI","executionInfo":{"elapsed":2815,"status":"ok","timestamp":1628596184198,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"},"user_tz":-60},"outputId":"07ee0940-3853-4ddd-8f48-59b9d352b413"},"source":["EPOCH=10\n","validation_split = .2\n","shuffle_dataset = True\n","random_seed= 42\n","MIN_LEN=249\n","MAX_LEN = 100000\n","CHUNK_LEN=512\n","\n","\n","print('Loading BERT tokenizer...')\n","bert_tokenizer = BertTokenizer.from_pretrained('bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12', do_lower_case=True)\n","\n","dataset=CustomDataset(\n","    tokenizer=bert_tokenizer,\n","    min_len=MIN_LEN,\n","    max_len=MAX_LEN,\n","    chunk_len=CHUNK_LEN,\n","    data=train_df)\n","\n","# Creating data indices for training and validation splits:\n","dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","if shuffle_dataset :\n","    np.random.seed(random_seed)\n","    np.random.shuffle(indices)\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","\n","#print(dataset[train_indices[0]])\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc846f3cee5247dba6a08fec6565cd0c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXmAUrXorfLJ","executionInfo":{"status":"ok","timestamp":1628661010016,"user_tz":-60,"elapsed":32655725,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"}},"outputId":"20966a9f-24dd-4bf7-9853-d0bc432e2fd2"},"source":["\n","lr=3e-5\n","\n","model=BERTClass().to(device)\n","optimizer=AdamW(model.parameters(), lr=lr)\n","#scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                        #num_warmup_steps = 0,\n","                                        #num_training_steps = num_training_steps)\n","val_losses=[]\n","batches_losses=[]\n","val_acc=[]\n","for epoch in range(EPOCH):\n","    t0 = time.time()\n","    idx = 0\n","    batches_losses_sum = 0\n","    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n","\n","    batches_losses_tmp=train_loop_fun1(dataset, train_indices, model, optimizer, device)\n","    epoch_loss=np.mean(batches_losses_tmp)\n","    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n","    t1=time.time()\n","    output, target, val_losses_tmp=eval_loop_fun1(dataset, val_indices, model, device)\n","    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n","    tmp_evaluate=evaluate(target.reshape(-1), output)\n","    print(f\"=====>\\t{tmp_evaluate}\")\n","    val_acc.append(tmp_evaluate['accuracy'])\n","    val_losses.append(val_losses_tmp)\n","    batches_losses.append(batches_losses_tmp)\n","#    torch.save(model, f\"model1/model_epoch{epoch+1}.pt\")    "],"execution_count":16,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","=============== EPOCH 1 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.6812, time = 0.30 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.3042, time = 49.01 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.2097, time = 61.63 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2427, time = 67.70 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2924, time = 76.72 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2980, time = 82.58 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2697, time = 85.08 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2945, time = 89.61 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2666, time = 95.59 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3278, time = 99.17 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2714, time = 108.92 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2357, time = 116.35 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3037, time = 117.10 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2465, time = 138.34 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2676, time = 136.13 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2874, time = 143.26 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3577, time = 157.71 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2799, time = 176.24 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2802, time = 191.55 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2774, time = 196.20 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3046, time = 213.22 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3462, time = 238.53 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2968, time = 251.35 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2741, time = 281.46 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3172, time = 320.81 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2891, time = 350.04 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2710, time = 396.90 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2643, time = 408.97 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2674, time = 480.44 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3683, time = 509.96 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2224, time = 574.63 secondes ___\n","\n","*** avg_loss : 0.29, time : ~104.0 min (6251.38 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 234.33 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 2 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1587, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2330, time = 48.63 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1884, time = 61.43 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2340, time = 67.68 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2924, time = 76.72 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2965, time = 82.42 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2685, time = 84.15 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2948, time = 89.89 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2637, time = 95.56 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3269, time = 99.11 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2708, time = 109.09 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2351, time = 116.21 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3023, time = 117.15 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2457, time = 138.62 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2674, time = 135.97 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2867, time = 143.19 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3598, time = 157.63 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2799, time = 175.97 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2828, time = 191.54 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2771, time = 195.98 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3058, time = 212.77 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3476, time = 238.48 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2966, time = 250.95 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2727, time = 281.38 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3149, time = 320.30 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2893, time = 349.79 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.6107, time = 397.05 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.4734, time = 409.49 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2643, time = 480.91 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3731, time = 510.29 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2220, time = 574.57 secondes ___\n","\n","*** avg_loss : 0.30, time : ~104.0 min (6249.04 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 234.86 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 3 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1601, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2293, time = 48.69 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1859, time = 61.39 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2330, time = 67.22 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2914, time = 76.81 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2959, time = 82.35 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2675, time = 84.21 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2938, time = 89.93 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2643, time = 95.42 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3283, time = 99.19 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2708, time = 108.83 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2350, time = 116.41 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3021, time = 117.11 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2457, time = 138.46 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2668, time = 135.88 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2869, time = 143.10 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3602, time = 157.39 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2800, time = 175.92 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2827, time = 191.89 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2774, time = 196.32 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3046, time = 213.02 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3465, time = 238.75 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2973, time = 251.11 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2714, time = 281.74 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3142, time = 320.64 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2886, time = 350.05 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2716, time = 396.90 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2648, time = 409.00 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2671, time = 480.74 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3689, time = 510.25 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2215, time = 574.46 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6249.27 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 235.11 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 4 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1560, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2292, time = 48.64 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1863, time = 61.33 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2333, time = 67.11 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2907, time = 76.64 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2950, time = 82.49 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2673, time = 83.99 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2939, time = 89.62 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2636, time = 95.58 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3271, time = 99.33 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2710, time = 108.53 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2346, time = 116.29 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3017, time = 116.64 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2456, time = 138.07 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2676, time = 135.90 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2874, time = 142.82 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3601, time = 157.47 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2798, time = 175.86 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2822, time = 191.51 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2774, time = 196.13 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3050, time = 212.92 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3476, time = 238.41 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2974, time = 250.85 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2694, time = 281.48 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3107, time = 320.73 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2888, time = 350.08 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2717, time = 397.33 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2638, time = 409.02 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2673, time = 481.08 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3674, time = 509.88 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2220, time = 574.81 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6246.55 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 235.50 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 5 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1549, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2276, time = 48.85 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1847, time = 61.55 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2316, time = 67.39 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2894, time = 76.88 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2951, time = 82.64 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2673, time = 84.05 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2927, time = 89.79 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2637, time = 95.87 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3261, time = 99.79 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2704, time = 109.04 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2349, time = 116.83 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.2995, time = 117.07 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2468, time = 138.61 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2673, time = 136.32 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2878, time = 143.11 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3595, time = 157.74 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2799, time = 176.26 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2815, time = 191.86 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2771, time = 196.48 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3042, time = 213.32 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3496, time = 238.86 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2979, time = 251.38 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2669, time = 281.89 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3062, time = 321.18 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2892, time = 350.41 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2711, time = 397.50 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2622, time = 408.85 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2674, time = 480.68 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3682, time = 509.87 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2236, time = 574.29 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6254.22 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 235.68 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 6 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1574, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2254, time = 48.79 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1818, time = 61.48 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2319, time = 67.31 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2882, time = 76.68 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2950, time = 82.33 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2665, time = 84.13 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2931, time = 89.63 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2633, time = 95.35 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3263, time = 99.36 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2702, time = 108.73 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2340, time = 116.10 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3010, time = 117.10 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2450, time = 138.13 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2663, time = 135.68 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2870, time = 143.01 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3598, time = 157.31 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2806, time = 176.00 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2803, time = 191.71 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2778, time = 196.01 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3039, time = 212.89 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3503, time = 238.54 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2974, time = 250.79 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2676, time = 281.38 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3064, time = 320.38 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2894, time = 349.59 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2718, time = 396.88 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2629, time = 408.89 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2679, time = 480.45 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3677, time = 510.20 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2219, time = 574.05 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6244.99 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 235.02 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 7 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1555, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2240, time = 48.74 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1805, time = 61.46 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2326, time = 67.29 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2886, time = 76.67 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2941, time = 82.43 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2659, time = 83.99 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2918, time = 89.76 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2636, time = 95.31 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3252, time = 99.23 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2700, time = 108.90 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2348, time = 116.05 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3004, time = 117.05 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2448, time = 138.11 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2655, time = 135.70 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2880, time = 143.18 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3602, time = 157.29 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2797, time = 176.03 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2808, time = 191.55 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2768, time = 196.07 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3029, time = 212.89 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3531, time = 238.48 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2983, time = 250.74 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2655, time = 281.49 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3042, time = 320.47 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2898, time = 349.93 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2710, time = 397.34 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2620, time = 409.41 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2677, time = 480.99 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3673, time = 510.15 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2225, time = 574.44 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6247.19 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 234.84 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 8 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1577, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2241, time = 48.81 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1809, time = 61.45 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2335, time = 67.30 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2877, time = 76.72 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2937, time = 82.46 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2663, time = 83.99 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2932, time = 89.95 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2636, time = 95.27 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3255, time = 99.42 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2698, time = 108.94 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2359, time = 116.24 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.2995, time = 116.74 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2445, time = 138.57 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2668, time = 135.98 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2871, time = 143.52 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3611, time = 157.33 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2806, time = 176.06 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2805, time = 191.63 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2771, time = 196.30 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3027, time = 212.95 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3508, time = 238.54 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2979, time = 251.01 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2652, time = 281.52 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3021, time = 320.57 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2891, time = 350.06 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2701, time = 397.43 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2614, time = 409.11 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2677, time = 481.10 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3682, time = 510.01 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2238, time = 574.48 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6249.37 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 235.15 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 9 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1561, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2237, time = 48.77 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1800, time = 61.45 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2333, time = 67.30 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2889, time = 76.77 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2948, time = 82.35 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2658, time = 83.84 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2924, time = 89.50 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2636, time = 95.48 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3249, time = 99.19 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2698, time = 108.56 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2350, time = 116.24 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.3007, time = 116.68 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2456, time = 138.22 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2669, time = 135.45 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2877, time = 142.67 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3604, time = 157.25 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2799, time = 175.96 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2800, time = 191.39 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2776, time = 196.28 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3036, time = 212.96 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3524, time = 238.47 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2994, time = 251.07 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2626, time = 281.21 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.2971, time = 320.40 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2876, time = 349.82 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2697, time = 396.99 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2579, time = 408.56 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2672, time = 480.69 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3684, time = 509.47 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2260, time = 573.93 secondes ___\n","\n","*** avg_loss : 0.28, time : ~104.0 min (6242.82 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 233.73 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n","\n","=============== EPOCH 10 / 10 ===============\n","\n","___ batch index = 0 / 7516 (0.00%), loss = 0.1510, time = 0.15 secondes ___\n","___ batch index = 250 / 7516 (3.33%), loss = 0.2233, time = 48.63 secondes ___\n","___ batch index = 500 / 7516 (6.65%), loss = 0.1796, time = 61.22 secondes ___\n","___ batch index = 750 / 7516 (9.98%), loss = 0.2329, time = 67.03 secondes ___\n","___ batch index = 1000 / 7516 (13.30%), loss = 0.2878, time = 76.60 secondes ___\n","___ batch index = 1250 / 7516 (16.63%), loss = 0.2945, time = 82.35 secondes ___\n","___ batch index = 1500 / 7516 (19.96%), loss = 0.2650, time = 83.74 secondes ___\n","___ batch index = 1750 / 7516 (23.28%), loss = 0.2921, time = 89.35 secondes ___\n","___ batch index = 2000 / 7516 (26.61%), loss = 0.2630, time = 95.35 secondes ___\n","___ batch index = 2250 / 7516 (29.94%), loss = 0.3240, time = 99.06 secondes ___\n","___ batch index = 2500 / 7516 (33.26%), loss = 0.2696, time = 108.44 secondes ___\n","___ batch index = 2750 / 7516 (36.59%), loss = 0.2348, time = 116.24 secondes ___\n","___ batch index = 3000 / 7516 (39.91%), loss = 0.2999, time = 116.47 secondes ___\n","___ batch index = 3250 / 7516 (43.24%), loss = 0.2443, time = 137.83 secondes ___\n","___ batch index = 3500 / 7516 (46.57%), loss = 0.2649, time = 135.47 secondes ___\n","___ batch index = 3750 / 7516 (49.89%), loss = 0.2879, time = 142.59 secondes ___\n","___ batch index = 4000 / 7516 (53.22%), loss = 0.3586, time = 157.26 secondes ___\n","___ batch index = 4250 / 7516 (56.55%), loss = 0.2785, time = 175.80 secondes ___\n","___ batch index = 4500 / 7516 (59.87%), loss = 0.2811, time = 191.50 secondes ___\n","___ batch index = 4750 / 7516 (63.20%), loss = 0.2775, time = 195.96 secondes ___\n","___ batch index = 5000 / 7516 (66.52%), loss = 0.3033, time = 212.87 secondes ___\n","___ batch index = 5250 / 7516 (69.85%), loss = 0.3495, time = 238.36 secondes ___\n","___ batch index = 5500 / 7516 (73.18%), loss = 0.2989, time = 250.75 secondes ___\n","___ batch index = 5750 / 7516 (76.50%), loss = 0.2634, time = 281.16 secondes ___\n","___ batch index = 6000 / 7516 (79.83%), loss = 0.3010, time = 320.29 secondes ___\n","___ batch index = 6250 / 7516 (83.16%), loss = 0.2883, time = 349.75 secondes ___\n","___ batch index = 6500 / 7516 (86.48%), loss = 0.2687, time = 396.82 secondes ___\n","___ batch index = 6750 / 7516 (89.81%), loss = 0.2608, time = 408.51 secondes ___\n","___ batch index = 7000 / 7516 (93.13%), loss = 0.2681, time = 480.19 secondes ___\n","___ batch index = 7250 / 7516 (96.46%), loss = 0.3670, time = 509.69 secondes ___\n","___ batch index = 7500 / 7516 (99.79%), loss = 0.2248, time = 574.08 secondes ___\n","\n","*** avg_loss : 0.28, time : ~103.0 min (6239.26 sec) ***\n","\n","==> evaluation : avg_loss = 0.26, time : 234.83 sec\n","\n","=====>\t{'accuracy': 0.0, 'nb exemple': 392300, 'true_prediction': 0, 'false_prediction': 7846}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h8FVHm4jrfLK","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1628661010018,"user_tz":-60,"elapsed":46,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"}},"outputId":"6e75607c-4c24-4024-8586-401db339b1e3"},"source":["pd.DataFrame(np.array([[np.mean(x) for x in batches_losses], [np.mean(x) for x in val_losses]]).T,\n","                   columns=['Training', 'Validation']).plot(title=\"loss\")"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fd69a1d5b50>"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"nhpfzucHrfLL","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1628661010321,"user_tz":-60,"elapsed":307,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"}},"outputId":"64a8054b-d8df-4f1e-adb0-3964b7d047ec"},"source":["pd.DataFrame(np.array(val_acc).T,\n","                   columns=['Validation']).plot(title=\"accuracy\")"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fd69a089790>"]},"metadata":{"tags":[]},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"sVrr6gTCCjBp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628661010810,"user_tz":-60,"elapsed":490,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"}},"outputId":"3c3a2d8a-182b-4bb3-d82b-9b00008407b3"},"source":["!nvidia-smi"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Wed Aug 11 05:50:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    50W / 250W |  16241MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4cDl3vzgzAYM","executionInfo":{"status":"ok","timestamp":1628661010811,"user_tz":-60,"elapsed":1,"user":{"displayName":"徐徐","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKHS4HcLFppqIMKwA4_99ChFxosLxi2hIAPGMZ=s64","userId":"16435972062661838604"}}},"source":[""],"execution_count":19,"outputs":[]}]}